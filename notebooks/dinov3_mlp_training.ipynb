{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipywidgets) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure_eval in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (12.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (2.4.1)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (0.24.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (12.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (1.8.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (4.57.6)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.14/site-packages (from requests->transformers) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy torch torchvision tqdm pillow scikit-learn transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 Restaurant Table Classification\n",
    "\n",
    "**Task:** Classify CCTV crops of restaurant tables as: `clean`, `dirty`, or `occupied`\n",
    "\n",
    "**Architecture:** Frozen DINOv3 backbone → CLS token + Attention-Pooled Patches → MLP Head\n",
    "\n",
    "**Key Features:**\n",
    "- Group-based train/val/test split (prevents data leakage from consecutive CCTV frames)\n",
    "- Attention pooling learns which patches matter (vs mean pooling)\n",
    "- Focal loss + class weights for imbalanced data\n",
    "\n",
    "**Requirements:** Python 3.10+ (DINOv3 uses modern type hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.5.2/libexec/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.14.2 (main, Dec  5 2025, 16:49:16) [Clang 16.0.0 (clang-1600.0.26.6)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoImageProcessor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "DINOV3_MODELS = {\n",
    "    \"small\": \"dinov3_vits16\",\n",
    "    \"base\": \"dinov3_vitb16\",\n",
    "    \"large\": \"dinov3_vitl16\",\n",
    "    \"huge\": \"dinov3_vith16plus\",\n",
    "}\n",
    "EMBED_DIMS = {\"small\": 384, \"base\": 768, \"large\": 1024, \"huge\": 1280}\n",
    "\n",
    "BACKBONE_SIZE = \"base\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.05\n",
    "WARMUP_RATIO = 0.1\n",
    "LABEL_SMOOTHING = 0.05  # Reduced from 0.1 - high smoothing hurts minority classes\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "DROPOUT = 0.4  # Increased from 0.3 - helps with small dataset\n",
    "\n",
    "FOCAL_LOSS_GAMMA = 2.0\n",
    "USE_CLASS_WEIGHTS = True\n",
    "\n",
    "AUGMENTATION = \"aggressive\"  # Changed from \"standard\" for better generalization\n",
    "\n",
    "# Mixup settings\n",
    "USE_MIXUP = True\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "# Attention pooling (vs mean pooling)\n",
    "USE_ATTN_POOL = True\n",
    "\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0  # Must be 0 on macOS with Jupyter due to multiprocessing spawn issues\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv3 base from HuggingFace...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeabd46474c4e3884cb11423c458549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed dim: 768\n",
      "Backbone params: 85,660,416\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv3 from HuggingFace (Meta's URL is returning 403)\n",
    "from transformers import AutoModel\n",
    "\n",
    "print(f\"Loading DINOv3 {BACKBONE_SIZE} from HuggingFace...\")\n",
    "from huggingface_hub import login\n",
    "login()  # Will prompt for token\n",
    "HF_MODELS = {\n",
    "    \"small\": \"facebook/dinov3-vits16-pretrain-lvd1689m\",\n",
    "    \"base\": \"facebook/dinov3-vitb16-pretrain-lvd1689m\",\n",
    "    \"large\": \"facebook/dinov3-vitl16-pretrain-lvd1689m\",\n",
    "}\n",
    "\n",
    "backbone = AutoModel.from_pretrained(HF_MODELS[BACKBONE_SIZE], trust_remote_code=True)\n",
    "\n",
    "embed_dim = EMBED_DIMS[BACKBONE_SIZE]\n",
    "print(f\"Embed dim: {embed_dim}\")\n",
    "print(f\"Backbone params: {sum(p.numel() for p in backbone.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['clean', 'dirty', 'occupied']\n",
      "Total images: 891\n",
      "\n",
      "Class distribution:\n",
      "  clean: 231 (25.9%)\n",
      "  dirty: 106 (11.9%)\n",
      "  occupied: 554 (62.2%)\n"
     ]
    }
   ],
   "source": [
    "full_dataset = datasets.ImageFolder(root=DATA_DIR)\n",
    "num_classes = len(full_dataset.classes)\n",
    "id2label = {i: c for i, c in enumerate(full_dataset.classes)}\n",
    "label2id = {c: i for i, c in id2label.items()}\n",
    "\n",
    "print(f\"Classes: {full_dataset.classes}\")\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "\n",
    "class_counts = Counter(full_dataset.targets)\n",
    "print(\"\\nClass distribution:\")\n",
    "for idx, count in sorted(class_counts.items()):\n",
    "    print(f\"  {id2label[idx]}: {count} ({100*count/len(full_dataset):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 unique session+table groups across 891 images\n",
      "Train: 669 | Val: 166 | Test: 56\n",
      "✓ No group leakage detected - splits are clean!\n",
      "Class weights: [1.3195266723632812, 2.896103858947754, 0.5271867513656616]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "\n",
    "def get_group_id(filepath):\n",
    "    \"\"\"Extract session+table group from filename to prevent data leakage.\n",
    "    \n",
    "    Filename format: IPC3_40a0f14d_3_1_Mimosas_IPC3_20251227113907_table_00_frame_0001_00m30s.jpg\n",
    "    Group = session_id + timestamp + table_num\n",
    "    \n",
    "    For files without this format (e.g., \"20.JPG\"), use the filename itself as group.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    # Check if it matches the expected format (has enough parts and contains \"table\")\n",
    "    if len(parts) >= 8 and 'table' in filename:\n",
    "        session_id = parts[1]      # 40a0f14d\n",
    "        timestamp = parts[5]       # 20251227113907\n",
    "        table = parts[6] + '_' + parts[7]  # table_00\n",
    "        return f\"{session_id}_{timestamp}_{table}\"\n",
    "    else:\n",
    "        # For other filename formats, use the filename as its own group\n",
    "        return filename\n",
    "\n",
    "# Get indices and labels\n",
    "indices = list(range(len(full_dataset)))\n",
    "labels = full_dataset.targets\n",
    "\n",
    "# Extract group for each sample\n",
    "groups = [get_group_id(full_dataset.samples[i][0]) for i in indices]\n",
    "unique_groups = set(groups)\n",
    "print(f\"Found {len(unique_groups)} unique session+table groups across {len(indices)} images\")\n",
    "\n",
    "# Group-based split: all images from same session+table go to same split\n",
    "gss_train = GroupShuffleSplit(n_splits=1, test_size=(VAL_RATIO + TEST_RATIO), random_state=SEED)\n",
    "train_idx, temp_idx = next(gss_train.split(indices, labels, groups))\n",
    "train_idx, temp_idx = list(train_idx), list(temp_idx)\n",
    "\n",
    "# Split temp into val/test (also group-based)\n",
    "temp_groups = [groups[i] for i in temp_idx]\n",
    "temp_labels = [labels[i] for i in temp_idx]\n",
    "gss_valtest = GroupShuffleSplit(n_splits=1, test_size=TEST_RATIO/(VAL_RATIO+TEST_RATIO), random_state=SEED)\n",
    "val_idx_rel, test_idx_rel = next(gss_valtest.split(range(len(temp_idx)), temp_labels, temp_groups))\n",
    "val_idx = [temp_idx[i] for i in val_idx_rel]\n",
    "test_idx = [temp_idx[i] for i in test_idx_rel]\n",
    "\n",
    "print(f\"Train: {len(train_idx)} | Val: {len(val_idx)} | Test: {len(test_idx)}\")\n",
    "\n",
    "# Verify no group leakage\n",
    "train_groups = set(groups[i] for i in train_idx)\n",
    "val_groups = set(groups[i] for i in val_idx)\n",
    "test_groups = set(groups[i] for i in test_idx)\n",
    "assert len(train_groups & val_groups) == 0, \"Leakage between train and val!\"\n",
    "assert len(train_groups & test_groups) == 0, \"Leakage between train and test!\"\n",
    "assert len(val_groups & test_groups) == 0, \"Leakage between val and test!\"\n",
    "print(\"✓ No group leakage detected - splits are clean!\")\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "train_labels = [labels[i] for i in train_idx]\n",
    "train_class_counts = Counter(train_labels)\n",
    "class_weights = torch.tensor([len(train_labels)/(num_classes*train_class_counts[i]) for i in range(num_classes)], dtype=torch.float32).to(device)\n",
    "sample_weights = [class_weights[labels[i]].item() for i in train_idx]\n",
    "print(f\"Class weights: {class_weights.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches - Train: 41 | Val: 11 | Test: 4\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "class DINOv3Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indices, augment=\"none\"):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.normalize = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        if augment == \"standard\":\n",
    "            self.augment = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), transforms.RandomRotation(10), transforms.ColorJitter(0.3, 0.3, 0.2), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        elif augment == \"aggressive\":\n",
    "            self.augment = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.6, 1.0)), transforms.RandomRotation(15), transforms.ColorJitter(0.4, 0.4, 0.3, 0.1), transforms.RandomGrayscale(0.1), transforms.GaussianBlur(3), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        else:\n",
    "            self.augment = None\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[self.indices[idx]]\n",
    "        if img.mode != \"RGB\": img = img.convert(\"RGB\")\n",
    "        return (self.augment or self.normalize)(img), label\n",
    "\n",
    "train_ds = DINOv3Dataset(full_dataset, train_idx, augment=AUGMENTATION)\n",
    "val_ds = DINOv3Dataset(full_dataset, val_idx)\n",
    "test_ds = DINOv3Dataset(full_dataset, test_idx)\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, len(train_idx), replacement=True)\n",
    "train_loader = DataLoader(train_ds, BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(f\"Batches - Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.label_smoothing = alpha, gamma, label_smoothing\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n",
    "        pt = torch.exp(-ce)\n",
    "        fl = (1-pt)**self.gamma * ce\n",
    "        return (self.alpha[targets] * fl if self.alpha is not None else fl).mean()\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Mixup: blend pairs of images and labels\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute loss for mixup\"\"\"\n",
    "    return lam * F.cross_entropy(pred, y_a) + (1 - lam) * F.cross_entropy(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    \"\"\"Learn which patches matter - finds local discriminative features.\n",
    "    \n",
    "    Unlike mean pooling which treats all patches equally, this learns to\n",
    "    focus on discriminative regions (e.g., dishes/debris for 'dirty' class).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):  # x: [B, N, D] (batch, num_patches, embed_dim)\n",
    "        weights = F.softmax(self.attn(x), dim=1)  # [B, N, 1]\n",
    "        return (weights * x).sum(dim=1)  # [B, D]\n",
    "\n",
    "\n",
    "class DINOv3Classifier(nn.Module):\n",
    "    def __init__(self, backbone, embed_dim, num_classes, head_type=\"3layer\", dropout=0.3, use_attn_pool=True):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        for p in backbone.parameters(): p.requires_grad = False\n",
    "        backbone.eval()\n",
    "        \n",
    "        # Attention pooling for patches (CLS token kept separate)\n",
    "        self.use_attn_pool = use_attn_pool\n",
    "        if use_attn_pool:\n",
    "            self.attn_pool = AttentionPool(embed_dim)\n",
    "        \n",
    "        # Feature dim = CLS (embed_dim) + pooled patches (embed_dim)\n",
    "        feat_dim = embed_dim * 2\n",
    "        if head_type == \"linear\":\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Dropout(dropout), nn.Linear(feat_dim, num_classes))\n",
    "        elif head_type == \"2layer\":\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Linear(feat_dim, 256), nn.GELU(), nn.Dropout(dropout), nn.Linear(256, num_classes))\n",
    "        else:  # 3layer\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Linear(feat_dim, 512), nn.GELU(), nn.Dropout(dropout), nn.Linear(512, 128), nn.GELU(), nn.Dropout(dropout), nn.Linear(128, num_classes))\n",
    "        self.head_type, self.embed_dim = head_type, embed_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = self.backbone(x)\n",
    "            if hasattr(out, 'last_hidden_state'):\n",
    "                cls_token = out.last_hidden_state[:, 0]\n",
    "                patches = out.last_hidden_state[:, 1:]\n",
    "            else:\n",
    "                cls_token = out['x_norm_clstoken']\n",
    "                patches = out['x_norm_patchtokens']\n",
    "        \n",
    "        # CLS keeps full weight, patches get attention-pooled (or mean-pooled as fallback)\n",
    "        if self.use_attn_pool:\n",
    "            pooled = self.attn_pool(patches)\n",
    "        else:\n",
    "            pooled = patches.mean(dim=1)\n",
    "        \n",
    "        features = torch.cat([cls_token, pooled], dim=1)\n",
    "        return self.head(features)\n",
    "    \n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        self.backbone.eval()  # Keep backbone frozen\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience, self.counter, self.best_score, self.best_state = patience, 0, None, None\n",
    "    def __call__(self, val_acc, model):\n",
    "        if self.best_score is None or val_acc > self.best_score + 0.001:\n",
    "            self.best_score, self.best_state, self.counter = val_acc, {k: v.cpu().clone() for k, v in model.state_dict().items()}, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device, use_mixup=False, mixup_alpha=0.2):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_mixup:\n",
    "            x, y_a, y_b, lam = mixup_data(x, y, mixup_alpha)\n",
    "            logits = model(x)\n",
    "            loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            # For accuracy, use the dominant label\n",
    "            correct += (lam * (logits.argmax(1) == y_a).float() + (1-lam) * (logits.argmax(1) == y_b).float()).sum().item()\n",
    "        else:\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        # Clip gradients for all trainable params (head + attn_pool)\n",
    "        trainable_params = list(model.head.parameters())\n",
    "        if hasattr(model, 'attn_pool') and model.use_attn_pool:\n",
    "            trainable_params += list(model.attn_pool.parameters())\n",
    "        torch.nn.utils.clip_grad_norm_(trainable_params, 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        total += y.size(0)\n",
    "    return total_loss/len(loader), correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total, preds, labels = 0, 0, 0, [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        total_loss += criterion(logits, y).item()\n",
    "        p = logits.argmax(1)\n",
    "        correct += (p == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        preds.extend(p.cpu().numpy())\n",
    "        labels.extend(y.cpu().numpy())\n",
    "    return total_loss/len(loader), correct/total, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config, device):\n",
    "    model = model.to(device)\n",
    "    criterion = FocalLoss(class_weights if USE_CLASS_WEIGHTS else None, FOCAL_LOSS_GAMMA, LABEL_SMOOTHING)\n",
    "    \n",
    "    # Collect all trainable parameters (head + attention pooling if used)\n",
    "    trainable_params = list(model.head.parameters())\n",
    "    if hasattr(model, 'attn_pool') and model.use_attn_pool:\n",
    "        trainable_params += list(model.attn_pool.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    warmup_steps = int(WARMUP_RATIO * total_steps)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda s: s/warmup_steps if s < warmup_steps else 0.5*(1+np.cos(np.pi*(s-warmup_steps)/(total_steps-warmup_steps))))\n",
    "    early_stopping = EarlyStopping(EARLY_STOPPING_PATIENCE)\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device, \n",
    "                                            use_mixup=USE_MIXUP, mixup_alpha=MIXUP_ALPHA)\n",
    "        val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: train_acc={100*train_acc:.1f}% val_acc={100*val_acc:.1f}%\")\n",
    "        if early_stopping(val_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    model.load_state_dict(early_stopping.best_state)\n",
    "    return model.to(device), early_stopping.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config: dropout=0.4, use_attn_pool=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b25876c213479280481262f841a4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc=41.5% val_acc=61.4%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa762133959345bc9da4c5d494c49a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_acc=72.2% val_acc=72.9%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8b6de2a5e94b2daba4691747ae268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_acc=79.2% val_acc=82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d818441eeb754a5da27529c059b6f78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_acc=82.1% val_acc=86.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27828674309145caae619a250984ef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc=88.2% val_acc=83.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf36ad04cf9436cbaf2b6a41ec78f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc=90.4% val_acc=86.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f7309761f54749bc514645a4dcdce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_acc=88.6% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750857a0f5f4406b655b6d8eab2a945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_acc=91.4% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891d0e22ed3145fc90c39428b72f0794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_acc=89.6% val_acc=86.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e48ddf78364160b82641d77ffcbd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_acc=87.1% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ac0e037aef4f788d56f40a52ea0fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_acc=93.9% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c191c8d1d23a4258a40ca3836920f2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_acc=90.5% val_acc=86.1%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8584e48a183a43e3917e35da61810274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_acc=91.2% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3b2e479f06442d8784e70265b77d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_acc=91.7% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d7188ebc9745c99ba3b1afd58fffbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_acc=91.1% val_acc=87.3%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ffb9ac212f48e7856dd940c08c1692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_acc=91.5% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3412cb0a254d66896b7ad182e649a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_acc=92.0% val_acc=89.2%\n",
      "Early stopping at epoch 17\n",
      "\n",
      "Best val accuracy: 89.16%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = DINOv3Classifier(backbone, embed_dim, num_classes, head_type=\"3layer\", dropout=DROPOUT, use_attn_pool=USE_ATTN_POOL)\n",
    "print(f\"Model config: dropout={DROPOUT}, use_attn_pool={USE_ATTN_POOL}\")\n",
    "config = {'epochs': NUM_EPOCHS, 'lr': LEARNING_RATE, 'weight_decay': WEIGHT_DECAY}\n",
    "model, best_acc = train_model(model, train_loader, val_loader, config, device)\n",
    "print(f\"\\nBest val accuracy: {100*best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.64%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.71      1.00      0.83         5\n",
      "       dirty       1.00      0.62      0.77         8\n",
      "    occupied       0.98      1.00      0.99        43\n",
      "\n",
      "    accuracy                           0.95        56\n",
      "   macro avg       0.90      0.88      0.86        56\n",
      "weighted avg       0.96      0.95      0.94        56\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "criterion = FocalLoss(class_weights, FOCAL_LOSS_GAMMA)\n",
    "_, test_acc, preds, labels = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {100*test_acc:.2f}%\\n\")\n",
    "print(classification_report(labels, preds, target_names=list(id2label.values())))\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=id2label.values(), yticklabels=id2label.values())\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to dinov3_classifier.pt\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "save_dict = {\n",
    "    'head': model.head.state_dict(),\n",
    "    'backbone': DINOV3_MODELS[BACKBONE_SIZE],\n",
    "    'embed_dim': embed_dim,\n",
    "    'id2label': id2label,\n",
    "    'use_attn_pool': USE_ATTN_POOL,\n",
    "}\n",
    "if USE_ATTN_POOL and hasattr(model, 'attn_pool'):\n",
    "    save_dict['attn_pool'] = model.attn_pool.state_dict()\n",
    "torch.save(save_dict, 'dinov3_classifier.pt')\n",
    "print(\"Model saved to dinov3_classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(labels, preds, target_names=\u001b[38;5;28mlist\u001b[39m(id2label.values())))\n",
      "\u001b[31mNameError\u001b[39m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds, target_names=list(id2label.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
