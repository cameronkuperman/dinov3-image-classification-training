{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINOv3 Restaurant Table Classification - V2\n",
    "\n",
    "**Task:** Classify CCTV crops of restaurant tables as: `clean`, `dirty`, or `occupied`\n",
    "\n",
    "**Architecture:** Frozen DINOv3 backbone → CLS token + Attention-Pooled Patches → MLP Head\n",
    "\n",
    "**V2 Changes:**\n",
    "- Lower weight decay (0.01 vs 0.05) - less aggressive for small head\n",
    "- Higher dropout (0.5 vs 0.4) - more regularization\n",
    "- 2x dirty class weight boost - prioritize minority class\n",
    "\n",
    "**Key Features:**\n",
    "- Group-based train/val/test split (prevents data leakage from consecutive CCTV frames)\n",
    "- Attention pooling learns which patches matter (vs mean pooling)\n",
    "- Focal loss + boosted class weights for imbalanced data\n",
    "\n",
    "**Requirements:** Python 3.10+ (DINOv3 uses modern type hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.12 (main, Oct  9 2025, 11:07:00) [Clang 17.0.0 (clang-1700.4.4.1)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoImageProcessor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - V2 (tuned hyperparameters)\n",
    "# =============================================================================\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "DINOV3_MODELS = {\n",
    "    \"small\": \"dinov3_vits16\",\n",
    "    \"base\": \"dinov3_vitb16\",\n",
    "    \"large\": \"dinov3_vitl16\",\n",
    "    \"huge\": \"dinov3_vith16plus\",\n",
    "}\n",
    "EMBED_DIMS = {\"small\": 384, \"base\": 768, \"large\": 1024, \"huge\": 1280}\n",
    "\n",
    "BACKBONE_SIZE = \"base\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.01  # Reduced from 0.05 - less aggressive for small head\n",
    "WARMUP_RATIO = 0.1\n",
    "LABEL_SMOOTHING = 0.05\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "DROPOUT = 0.5  # Increased from 0.4 - more regularization\n",
    "\n",
    "FOCAL_LOSS_GAMMA = 2.0\n",
    "USE_CLASS_WEIGHTS = True\n",
    "DIRTY_WEIGHT_BOOST = 2.0  # Extra boost for dirty class\n",
    "\n",
    "AUGMENTATION = \"aggressive\"\n",
    "\n",
    "# Mixup settings\n",
    "USE_MIXUP = True\n",
    "MIXUP_ALPHA = 0.2\n",
    "\n",
    "# Attention pooling (vs mean pooling)\n",
    "USE_ATTN_POOL = True\n",
    "\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv3 base from HuggingFace...\n",
      "Embed dim: 768\n",
      "Backbone params: 85,660,416\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv3 from HuggingFace (Meta's URL is returning 403)\n",
    "from transformers import AutoModel\n",
    "\n",
    "print(f\"Loading DINOv3 {BACKBONE_SIZE} from HuggingFace...\")\n",
    "\n",
    "HF_MODELS = {\n",
    "    \"small\": \"facebook/dinov3-vits16-pretrain-lvd1689m\",\n",
    "    \"base\": \"facebook/dinov3-vitb16-pretrain-lvd1689m\",\n",
    "    \"large\": \"facebook/dinov3-vitl16-pretrain-lvd1689m\",\n",
    "}\n",
    "\n",
    "backbone = AutoModel.from_pretrained(HF_MODELS[BACKBONE_SIZE], trust_remote_code=True)\n",
    "\n",
    "embed_dim = EMBED_DIMS[BACKBONE_SIZE]\n",
    "print(f\"Embed dim: {embed_dim}\")\n",
    "print(f\"Backbone params: {sum(p.numel() for p in backbone.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['clean', 'dirty', 'occupied']\n",
      "Total images: 891\n",
      "\n",
      "Class distribution:\n",
      "  clean: 231 (25.9%)\n",
      "  dirty: 106 (11.9%)\n",
      "  occupied: 554 (62.2%)\n"
     ]
    }
   ],
   "source": [
    "full_dataset = datasets.ImageFolder(root=DATA_DIR)\n",
    "num_classes = len(full_dataset.classes)\n",
    "id2label = {i: c for i, c in enumerate(full_dataset.classes)}\n",
    "label2id = {c: i for i, c in id2label.items()}\n",
    "\n",
    "print(f\"Classes: {full_dataset.classes}\")\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "\n",
    "class_counts = Counter(full_dataset.targets)\n",
    "print(\"\\nClass distribution:\")\n",
    "for idx, count in sorted(class_counts.items()):\n",
    "    print(f\"  {id2label[idx]}: {count} ({100*count/len(full_dataset):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 unique session+table groups across 891 images\n",
      "Train: 669 | Val: 166 | Test: 56\n",
      "✓ No group leakage detected - splits are clean!\n",
      "Original dirty weight: 2.90\n",
      "Boosted dirty weight: 5.79 (x2.0)\n",
      "Class weights: [1.3195266723632812, 5.792207717895508, 0.5271867513656616]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "\n",
    "def get_group_id(filepath):\n",
    "    \"\"\"Extract session+table group from filename to prevent data leakage.\n",
    "    \n",
    "    Filename format: IPC3_40a0f14d_3_1_Mimosas_IPC3_20251227113907_table_00_frame_0001_00m30s.jpg\n",
    "    Group = session_id + timestamp + table_num\n",
    "    \n",
    "    For files without this format (e.g., \"20.JPG\"), use the filename itself as group.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    # Check if it matches the expected format (has enough parts and contains \"table\")\n",
    "    if len(parts) >= 8 and 'table' in filename:\n",
    "        session_id = parts[1]      # 40a0f14d\n",
    "        timestamp = parts[5]       # 20251227113907\n",
    "        table = parts[6] + '_' + parts[7]  # table_00\n",
    "        return f\"{session_id}_{timestamp}_{table}\"\n",
    "    else:\n",
    "        # For other filename formats, use the filename as its own group\n",
    "        return filename\n",
    "\n",
    "# Get indices and labels\n",
    "indices = list(range(len(full_dataset)))\n",
    "labels = full_dataset.targets\n",
    "\n",
    "# Extract group for each sample\n",
    "groups = [get_group_id(full_dataset.samples[i][0]) for i in indices]\n",
    "unique_groups = set(groups)\n",
    "print(f\"Found {len(unique_groups)} unique session+table groups across {len(indices)} images\")\n",
    "\n",
    "# Group-based split: all images from same session+table go to same split\n",
    "gss_train = GroupShuffleSplit(n_splits=1, test_size=(VAL_RATIO + TEST_RATIO), random_state=SEED)\n",
    "train_idx, temp_idx = next(gss_train.split(indices, labels, groups))\n",
    "train_idx, temp_idx = list(train_idx), list(temp_idx)\n",
    "\n",
    "# Split temp into val/test (also group-based)\n",
    "temp_groups = [groups[i] for i in temp_idx]\n",
    "temp_labels = [labels[i] for i in temp_idx]\n",
    "gss_valtest = GroupShuffleSplit(n_splits=1, test_size=TEST_RATIO/(VAL_RATIO+TEST_RATIO), random_state=SEED)\n",
    "val_idx_rel, test_idx_rel = next(gss_valtest.split(range(len(temp_idx)), temp_labels, temp_groups))\n",
    "val_idx = [temp_idx[i] for i in val_idx_rel]\n",
    "test_idx = [temp_idx[i] for i in test_idx_rel]\n",
    "\n",
    "print(f\"Train: {len(train_idx)} | Val: {len(val_idx)} | Test: {len(test_idx)}\")\n",
    "\n",
    "# Verify no group leakage\n",
    "train_groups = set(groups[i] for i in train_idx)\n",
    "val_groups = set(groups[i] for i in val_idx)\n",
    "test_groups = set(groups[i] for i in test_idx)\n",
    "assert len(train_groups & val_groups) == 0, \"Leakage between train and val!\"\n",
    "assert len(train_groups & test_groups) == 0, \"Leakage between train and test!\"\n",
    "assert len(val_groups & test_groups) == 0, \"Leakage between val and test!\"\n",
    "print(\"✓ No group leakage detected - splits are clean!\")\n",
    "\n",
    "# Class weights for imbalanced data\n",
    "train_labels = [labels[i] for i in train_idx]\n",
    "train_class_counts = Counter(train_labels)\n",
    "class_weights = torch.tensor([len(train_labels)/(num_classes*train_class_counts[i]) for i in range(num_classes)], dtype=torch.float32).to(device)\n",
    "\n",
    "# Boost dirty class weight\n",
    "dirty_idx = label2id['dirty']\n",
    "print(f\"Original dirty weight: {class_weights[dirty_idx].item():.2f}\")\n",
    "class_weights[dirty_idx] *= DIRTY_WEIGHT_BOOST\n",
    "print(f\"Boosted dirty weight: {class_weights[dirty_idx].item():.2f} (x{DIRTY_WEIGHT_BOOST})\")\n",
    "\n",
    "sample_weights = [class_weights[labels[i]].item() for i in train_idx]\n",
    "print(f\"Class weights: {class_weights.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches - Train: 41 | Val: 11 | Test: 4\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "class DINOv3Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indices, augment=\"none\"):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.normalize = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        if augment == \"standard\":\n",
    "            self.augment = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), transforms.RandomRotation(10), transforms.ColorJitter(0.3, 0.3, 0.2), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        elif augment == \"aggressive\":\n",
    "            self.augment = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.6, 1.0)), transforms.RandomRotation(15), transforms.ColorJitter(0.4, 0.4, 0.3, 0.1), transforms.RandomGrayscale(0.1), transforms.GaussianBlur(3), transforms.ToTensor(), transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n",
    "        else:\n",
    "            self.augment = None\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[self.indices[idx]]\n",
    "        if img.mode != \"RGB\": img = img.convert(\"RGB\")\n",
    "        return (self.augment or self.normalize)(img), label\n",
    "\n",
    "train_ds = DINOv3Dataset(full_dataset, train_idx, augment=AUGMENTATION)\n",
    "val_ds = DINOv3Dataset(full_dataset, val_idx)\n",
    "test_ds = DINOv3Dataset(full_dataset, test_idx)\n",
    "\n",
    "sampler = WeightedRandomSampler(sample_weights, len(train_idx), replacement=True)\n",
    "train_loader = DataLoader(train_ds, BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(f\"Batches - Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.label_smoothing = alpha, gamma, label_smoothing\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n",
    "        pt = torch.exp(-ce)\n",
    "        fl = (1-pt)**self.gamma * ce\n",
    "        return (self.alpha[targets] * fl if self.alpha is not None else fl).mean()\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Mixup: blend pairs of images and labels\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute loss for mixup\"\"\"\n",
    "    return lam * F.cross_entropy(pred, y_a) + (1 - lam) * F.cross_entropy(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    \"\"\"Learn which patches matter - finds local discriminative features.\n",
    "    \n",
    "    Unlike mean pooling which treats all patches equally, this learns to\n",
    "    focus on discriminative regions (e.g., dishes/debris for 'dirty' class).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):  # x: [B, N, D] (batch, num_patches, embed_dim)\n",
    "        weights = F.softmax(self.attn(x), dim=1)  # [B, N, 1]\n",
    "        return (weights * x).sum(dim=1)  # [B, D]\n",
    "\n",
    "\n",
    "class DINOv3Classifier(nn.Module):\n",
    "    def __init__(self, backbone, embed_dim, num_classes, head_type=\"3layer\", dropout=0.3, use_attn_pool=True):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        for p in backbone.parameters(): p.requires_grad = False\n",
    "        backbone.eval()\n",
    "        \n",
    "        # Attention pooling for patches (CLS token kept separate)\n",
    "        self.use_attn_pool = use_attn_pool\n",
    "        if use_attn_pool:\n",
    "            self.attn_pool = AttentionPool(embed_dim)\n",
    "        \n",
    "        # Feature dim = CLS (embed_dim) + pooled patches (embed_dim)\n",
    "        feat_dim = embed_dim * 2\n",
    "        if head_type == \"linear\":\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Dropout(dropout), nn.Linear(feat_dim, num_classes))\n",
    "        elif head_type == \"2layer\":\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Linear(feat_dim, 256), nn.GELU(), nn.Dropout(dropout), nn.Linear(256, num_classes))\n",
    "        else:  # 3layer\n",
    "            self.head = nn.Sequential(nn.LayerNorm(feat_dim), nn.Linear(feat_dim, 512), nn.GELU(), nn.Dropout(dropout), nn.Linear(512, 128), nn.GELU(), nn.Dropout(dropout), nn.Linear(128, num_classes))\n",
    "        self.head_type, self.embed_dim = head_type, embed_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = self.backbone(x)\n",
    "            if hasattr(out, 'last_hidden_state'):\n",
    "                cls_token = out.last_hidden_state[:, 0]\n",
    "                patches = out.last_hidden_state[:, 1:]\n",
    "            else:\n",
    "                cls_token = out['x_norm_clstoken']\n",
    "                patches = out['x_norm_patchtokens']\n",
    "        \n",
    "        # CLS keeps full weight, patches get attention-pooled (or mean-pooled as fallback)\n",
    "        if self.use_attn_pool:\n",
    "            pooled = self.attn_pool(patches)\n",
    "        else:\n",
    "            pooled = patches.mean(dim=1)\n",
    "        \n",
    "        features = torch.cat([cls_token, pooled], dim=1)\n",
    "        return self.head(features)\n",
    "    \n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        self.backbone.eval()  # Keep backbone frozen\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience, self.counter, self.best_score, self.best_state = patience, 0, None, None\n",
    "    def __call__(self, val_acc, model):\n",
    "        if self.best_score is None or val_acc > self.best_score + 0.001:\n",
    "            self.best_score, self.best_state, self.counter = val_acc, {k: v.cpu().clone() for k, v in model.state_dict().items()}, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device, use_mixup=False, mixup_alpha=0.2):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if use_mixup:\n",
    "            x, y_a, y_b, lam = mixup_data(x, y, mixup_alpha)\n",
    "            logits = model(x)\n",
    "            loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            # For accuracy, use the dominant label\n",
    "            correct += (lam * (logits.argmax(1) == y_a).float() + (1-lam) * (logits.argmax(1) == y_b).float()).sum().item()\n",
    "        else:\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        # Clip gradients for all trainable params (head + attn_pool)\n",
    "        trainable_params = list(model.head.parameters())\n",
    "        if hasattr(model, 'attn_pool') and model.use_attn_pool:\n",
    "            trainable_params += list(model.attn_pool.parameters())\n",
    "        torch.nn.utils.clip_grad_norm_(trainable_params, 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        total += y.size(0)\n",
    "    return total_loss/len(loader), correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total, preds, labels = 0, 0, 0, [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        total_loss += criterion(logits, y).item()\n",
    "        p = logits.argmax(1)\n",
    "        correct += (p == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        preds.extend(p.cpu().numpy())\n",
    "        labels.extend(y.cpu().numpy())\n",
    "    return total_loss/len(loader), correct/total, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config, device):\n",
    "    model = model.to(device)\n",
    "    criterion = FocalLoss(class_weights if USE_CLASS_WEIGHTS else None, FOCAL_LOSS_GAMMA, LABEL_SMOOTHING)\n",
    "    \n",
    "    # Collect all trainable parameters (head + attention pooling if used)\n",
    "    trainable_params = list(model.head.parameters())\n",
    "    if hasattr(model, 'attn_pool') and model.use_attn_pool:\n",
    "        trainable_params += list(model.attn_pool.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    warmup_steps = int(WARMUP_RATIO * total_steps)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda s: s/warmup_steps if s < warmup_steps else 0.5*(1+np.cos(np.pi*(s-warmup_steps)/(total_steps-warmup_steps))))\n",
    "    early_stopping = EarlyStopping(EARLY_STOPPING_PATIENCE)\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device, \n",
    "                                            use_mixup=USE_MIXUP, mixup_alpha=MIXUP_ALPHA)\n",
    "        val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: train_acc={100*train_acc:.1f}% val_acc={100*val_acc:.1f}%\")\n",
    "        if early_stopping(val_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    model.load_state_dict(early_stopping.best_state)\n",
    "    return model.to(device), early_stopping.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config: dropout=0.5, use_attn_pool=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66a0cc13f87457fbc9ce1c114aa9bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc=37.0% val_acc=13.9%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8938a0b3e2294446ba56738ae3329eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_acc=57.3% val_acc=43.4%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca91f7579344b829473510b249d952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_acc=77.9% val_acc=81.3%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3562028a03f44e2a4e81328f69bb1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_acc=80.7% val_acc=83.1%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e796782b18e483fa40b6003c9cd72f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc=88.2% val_acc=82.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b2d760204a4ee0bcc459c47c630c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc=89.9% val_acc=87.3%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dd48af98764165b135b5f10c6254b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_acc=89.7% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9906d2f9215c4ec0886980ba37d5c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_acc=89.8% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb140c651a4f7ab578ad6232ee6415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_acc=88.6% val_acc=84.9%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c87ae835e0f499881aed5e889fed4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_acc=87.9% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8573e2c04c7f4fb4b82cd246fb40e00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_acc=93.3% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e535aeb7494c9f982404cd5157f95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_acc=92.2% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3717d98198e542a89b83572e673bbf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_acc=91.5% val_acc=90.4%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64e77a843f3470f9729de488cec14e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_acc=90.4% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ca708c22b142e993cfb06834d65ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_acc=89.6% val_acc=84.3%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf82473355e64588a3ada245c3f23633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_acc=90.7% val_acc=86.7%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68095fccd00e4ef4891f383f66d18c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_acc=92.1% val_acc=89.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90d59517ef4d8e918925ff793129a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_acc=90.3% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1aceeac9784456990b49f32aa9274c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_acc=92.0% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd58b9ec23240acb1dba81dca7e7212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_acc=93.3% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b104be0ad0d47a89516cbabfd90787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_acc=92.4% val_acc=91.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20c1408b06f407781c37d055e206945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_acc=91.1% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0374d1a8a642df9e251d668a254548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_acc=89.9% val_acc=88.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a56908f3684a63aa22eb023a07136e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_acc=91.7% val_acc=89.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505d7bdc5bb34c73b880dc0caf1f796d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_acc=94.0% val_acc=90.4%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246218792d4e42b9a4f398df09d71786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_acc=92.1% val_acc=89.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb2b2f4abbc44ad9330f807610336ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_acc=93.0% val_acc=89.8%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d9a0e32ad64cd9b04ec4e6f2dae79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_acc=93.4% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738ef2f97c594456b255c683a0d40e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_acc=92.7% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21d6e3312024246a4e25234011f1588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_acc=91.9% val_acc=88.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5843c4640084397badf97cdb0c5b46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_acc=89.9% val_acc=89.2%\n",
      "Early stopping at epoch 31\n",
      "\n",
      "Best val accuracy: 90.96%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = DINOv3Classifier(backbone, embed_dim, num_classes, head_type=\"3layer\", dropout=DROPOUT, use_attn_pool=USE_ATTN_POOL)\n",
    "print(f\"Model config: dropout={DROPOUT}, use_attn_pool={USE_ATTN_POOL}\")\n",
    "config = {'epochs': NUM_EPOCHS, 'lr': LEARNING_RATE, 'weight_decay': WEIGHT_DECAY}\n",
    "model, best_acc = train_model(model, train_loader, val_loader, config, device)\n",
    "print(f\"\\nBest val accuracy: {100*best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.29%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.45      1.00      0.62         5\n",
      "       dirty       1.00      0.25      0.40         8\n",
      "    occupied       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           0.89        56\n",
      "   macro avg       0.82      0.75      0.67        56\n",
      "weighted avg       0.95      0.89      0.88        56\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "criterion = FocalLoss(class_weights, FOCAL_LOSS_GAMMA)\n",
    "_, test_acc, preds, labels = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {100*test_acc:.2f}%\\n\")\n",
    "print(classification_report(labels, preds, target_names=list(id2label.values())))\n",
    "\n",
    "cm = confusion_matrix(labels, preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=id2label.values(), yticklabels=id2label.values())\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to dinov3_classifier.pt\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "save_dict = {\n",
    "    'head': model.head.state_dict(),\n",
    "    'backbone': DINOV3_MODELS[BACKBONE_SIZE],\n",
    "    'embed_dim': embed_dim,\n",
    "    'id2label': id2label,\n",
    "    'use_attn_pool': USE_ATTN_POOL,\n",
    "}\n",
    "if USE_ATTN_POOL and hasattr(model, 'attn_pool'):\n",
    "    save_dict['attn_pool'] = model.attn_pool.state_dict()\n",
    "torch.save(save_dict, 'dinov3_classifier.pt')\n",
    "print(\"Model saved to dinov3_classifier.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
